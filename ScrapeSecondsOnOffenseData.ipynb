{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d562f50a-2658-463f-93c1-66d7910e35d8",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc857eb-ce9c-44e4-bfc6-b4ab089335db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import selenium\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c018d51-f235-4b48-9822-70c13ba33f6c",
   "metadata": {},
   "source": [
    "#### Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea9c5c3-78b1-4410-93cc-6bcc9728fe60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _open_chromedriver(download_directory=r'C:\\Users\\lukar\\Desktop\\Sports Analytics\\NBA Ball Handle Rate\\data\\seconds-per-possession'):\n",
    "    '''\n",
    "    returns browser object of chromedriver with a specified download directory\n",
    "    '''\n",
    "    # create chromeOptions object\n",
    "    chrome_options = Options()\n",
    "    \n",
    "    prefs = {\"download.default_directory\" : download_directory}\n",
    "    chrome_options.add_experimental_option(\"prefs\",prefs)\n",
    "    \n",
    "    browser = webdriver.Chrome(options=chrome_options)\n",
    "    return browser\n",
    "\n",
    "def _scrape_table_data(browser, season, team_id, folderpath, rs=True):\n",
    "    '''\n",
    "    returns browser object & scrapes a specific table on the page and saves it to a local directory\n",
    "    '''\n",
    "    data = []\n",
    "    attempts = 0\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            \n",
    "            # find table parent element\n",
    "            table_parent = browser.find_element(By.ID, 'vgt-table')\n",
    "\n",
    "            # find tbody element within parent\n",
    "            tbody = table_parent.find_element(By.TAG_NAME, 'tbody')\n",
    "\n",
    "            # iterate over all the table rows & extract cell data\n",
    "            rows = tbody.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "            columns = ['PLAYER_NAME','MINUTES_ON','MINUTES_OFF',\n",
    "                       'SECONDS_PER_POSS_OFFENSE_PLAYER_ON','SECONDS_PER_POSS_OFFENSE_PLAYER_OFF','SECONDS_PER_POSS_OFFENSE_PLAYER_ON_OFF',\n",
    "                       'SEASON','TEAM_ID']\n",
    "            data = []\n",
    "\n",
    "            # iterate over all the table rows and extract cell data text\n",
    "            for row in rows:\n",
    "                # create empty lst to store player data\n",
    "                player_data = []\n",
    "\n",
    "                # get all the cells in the row\n",
    "                cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "\n",
    "                # iterate over the cells and extract the cell text\n",
    "                for cell in cells:\n",
    "                    player_data.append(cell.text)\n",
    "\n",
    "                player_data.append(season)\n",
    "                player_data.append(team_id)\n",
    "\n",
    "                # append player data to list\n",
    "                data.append(player_data)\n",
    "            \n",
    "            break\n",
    "                \n",
    "        except:\n",
    "            if (attempts == 10):\n",
    "                print(\"There was an error scraping data for the following team: {} | {}\".format(team_id, season))\n",
    "                break\n",
    "                \n",
    "            # find the button and click it           \n",
    "            button = browser.find_element(By.XPATH, '/html/body/div/div/main/div[2]/button')\n",
    "            button.click()\n",
    "            \n",
    "            time.sleep(2)\n",
    "                \n",
    "            attempts += 1\n",
    "            \n",
    "    # create dataframe\n",
    "    if rs:\n",
    "        team_seconds_df = pd.DataFrame(data, columns=columns)\n",
    "        team_seconds_df.to_csv(folderpath + \"{}_rs_seconds_per_poss_offense_{}.csv\".format(team_id, season), index=False)\n",
    "    else:\n",
    "        if data != []:\n",
    "            team_seconds_df = pd.DataFrame(data, columns=columns)\n",
    "            team_seconds_df.to_csv(folderpath + \"{}_playoffs_seconds_per_poss_offense_{}.csv\".format(team_id, season), index=False)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return browser\n",
    "\n",
    "def _scrape_rs_seconds_per_offense(browser, start_year=2013, end_year=2023, teams_lst=teams.get_teams(), folderpath=\"data/seconds-per-possession/regular-season/\"):\n",
    "    '''\n",
    "    returns nothing, but downloads a .csv file of seconds per possession - offense to a local directory given parameters to a specific URL\n",
    "    '''\n",
    "    print('Starting to Scrape Regular Season: Seconds per Possession - Offense Data...')\n",
    "    \n",
    "    # iterate through the seasons\n",
    "    for season in tqdm(range(start_year, end_year)):\n",
    "        season_param = str(season) + '-' + str(season+1)[2:]\n",
    "        \n",
    "        # iterate through all the teams\n",
    "        for team in teams_lst:\n",
    "            team_id = team['id']\n",
    "            \n",
    "            # input URL into browser and let it load\n",
    "            url = \"https://www.pbpstats.com/on-off/nba/stat?Season={}&SeasonType=Regular%2BSeason&TeamId={}&Stat=SecondsPerPossOff\".format(season_param, team_id)\n",
    "            browser.get(url)\n",
    "            \n",
    "            time.sleep(8)\n",
    "            \n",
    "            browser = _scrape_table_data(browser, season_param, team_id, folderpath)\n",
    "    \n",
    "    print('Finished Scraping Regular Season: Seconds per Possession - Offense Data!')\n",
    "    \n",
    "    return \n",
    "\n",
    "def _scrape_playoffs_seconds_per_offense(browser, start_year=2013, end_year=2023, teams_lst=teams.get_teams(), folderpath=\"data/seconds-per-possession/playoffs/\"):\n",
    "    '''\n",
    "    returns nothing, but downloads a .csv file of seconds per possession - offense to a local directory given parameters to a specific URL\n",
    "    '''\n",
    "    print('Starting to Scrape Playoffs: Seconds per Possession - Offense Data...')\n",
    "    \n",
    "    # iterate through the seasons\n",
    "    for season in tqdm(range(start_year, end_year)):\n",
    "        season_param = str(season) + '-' + str(season+1)[2:]\n",
    "        \n",
    "        # iterate through all the teams\n",
    "        for team in teams_lst:\n",
    "            team_id = team['id']\n",
    "            \n",
    "            # input URL into browser and let it load\n",
    "            url = \"https://www.pbpstats.com/on-off/nba/stat?Season={}&SeasonType=Playoffs&TeamId={}&Stat=SecondsPerPossOff\".format(season_param, team_id)\n",
    "            browser.get(url)\n",
    "            \n",
    "            time.sleep(8)\n",
    "            \n",
    "            browser = _scrape_table_data(browser, season_param, team_id, folderpath, rs=False)\n",
    "\n",
    "    print('Finished Scraping Playoffs: Seconds per Possession - Offense Data!')\n",
    "            \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06637599-1d85-42d9-ba5e-8372930efa20",
   "metadata": {},
   "source": [
    "#### Scrape the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5873255-0d81-48b6-b179-ea1219a8be6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to Scrape Regular Season: Seconds per Possession - Offense Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Scraping Regular Season: Seconds per Possession - Offense Data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "browser = _open_chromedriver()\n",
    "_scrape_rs_seconds_per_offense(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a66d3b0-fa80-47a8-bcdd-363b906a570b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to Scrape Playoffs: Seconds per Possession - Offense Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Scraping Playoffs: Seconds per Possession - Offense Data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "browser = _open_chromedriver()\n",
    "_scrape_playoffs_seconds_per_offense(browser)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
